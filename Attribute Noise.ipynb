{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model import dataClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f38c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "curated_bow = pd.read_csv('class_noise_cleaned.csv')\n",
    "curated_bow = curated_bow.drop(['contents'], axis=1)\n",
    "curated_bow.dropna()\n",
    "\n",
    "# Remove Trailing Spaces in Column Names\n",
    "curated_bow.columns = [col.strip() for col in curated_bow.columns]\n",
    "\n",
    "# Duplicate Columns Removed\n",
    "curated_bow = curated_bow.loc[:,~curated_bow.columns.duplicated()].copy()\n",
    "curated_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_ = 1\n",
    "bin_size = len(curated_bow.index)//partitions_ \n",
    "print(bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdffe4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ATNODE():\n",
    "    bins_counter = 0\n",
    "    partition_values = pd.DataFrame()\n",
    "    j_col= pd.DataFrame()\n",
    "    \n",
    "    for j in range(len(curated_bow.columns)):\n",
    "        start_j = time.time()\n",
    "        clustered_att = curated_bow.sort_values(by = curated_bow.columns[j])\n",
    "        \n",
    "        bins_counter = 0\n",
    "        \n",
    "        parition_mean = clustered_att.iloc[bins_counter: bins_counter + bin_size, j].values.mean()\n",
    "        partition_sd = clustered_att.iloc[bins_counter: bins_counter + bin_size, j].values.std()\n",
    "        mean_over_sd = parition_mean/partition_sd if partition_sd else 0\n",
    "\n",
    "        noise_score = pd.DataFrame([np.nan_to_num(abs(x - (mean_over_sd)))\n",
    "                                    for x in clustered_att.iloc[bins_counter:bins_counter + bin_size, j]])\n",
    "\n",
    "        partition_values = pd.concat([partition_values, noise_score], axis=0)\n",
    "                    \n",
    "        #dropping existing indices with the same name and replacing them with new, using reset index\n",
    "        partition_values= partition_values.reset_index(drop=True) \n",
    "        bins_counter = bins_counter + bin_size\n",
    "            \n",
    "        j_col= pd.concat([j_col, partition_values], axis= 1)\n",
    "        partition_values.drop(partition_values.index, inplace=True)\n",
    "        \n",
    "        end_j = time.time()\n",
    "        \n",
    "        time_df = end_j - start_j\n",
    "        time_df = format(time_df, '.6f')\n",
    "        \n",
    "        print(f\"Runtime of ATNODE for j ({j})\\t:\\t{time_df}\")\n",
    "        \n",
    "    return j_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf3b6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "atnode = run_ATNODE()\n",
    "atnode['max_noise'] = atnode.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b43fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_bow.insert(len(curated_bow.columns)-1, 'max_noise', atnode['max_noise'])\n",
    "curated_bow = curated_bow.sort_values(by=['max_noise'], ascending=False)\n",
    "curated_bow = curated_bow.reset_index()\n",
    "curated_bow = curated_bow.drop(['index'], axis=1)\n",
    "curated_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1d0bf3",
   "metadata": {},
   "source": [
    "## n Estimator = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8216a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rslts_df_100 = pd.DataFrame(columns = [\"k\", \"Accuracy\", \"Precision\", \"Recall\", \"F_Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546072f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rslts_100 = []\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f_scores = []\n",
    "\n",
    "k = 0\n",
    "\n",
    "print(\"N-Estimator = 100 \\n\\n\")\n",
    "\n",
    "for x in range(11):\n",
    "    an_cleaned = curated_bow.copy()\n",
    "    \n",
    "    n = round((k/100) * an_cleaned.shape[0])\n",
    "    \n",
    "    print(f\"Results after Removing top {k}% data\")\n",
    "    \n",
    "    an_cleaned = an_cleaned.iloc[n:]\n",
    "    last_col_index = len(an_cleaned.columns)-1\n",
    "    \n",
    "    X = an_cleaned.iloc[:, 0:last_col_index]\n",
    "    y = an_cleaned.iloc[:, -1]\n",
    "    \n",
    "    attrNoiseObj = dataClassifier(X, y)\n",
    "    attrNoiseObj.dataAnalysis(100)\n",
    "    \n",
    "    acc = round(attrNoiseObj.accuracy, 3)\n",
    "    pre = round(attrNoiseObj.precision, 3)\n",
    "    rec = round(attrNoiseObj.recall, 3)\n",
    "    f_score = round(attrNoiseObj.f_score, 3)\n",
    "\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Precision: {pre}\")\n",
    "    print(f\"Recall: {rec}\")\n",
    "    print(f\"F-Score: {f_score}\")\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    precisions.append(pre)\n",
    "    recalls.append(rec)\n",
    "    f_scores.append(f_score)\n",
    "    \n",
    "    data = {\n",
    "        \"k\": k,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": pre,\n",
    "        \"Recall\": rec,\n",
    "        \"F_Score\": f_score\n",
    "    }\n",
    "    \n",
    "    rslts_df_100.loc[len(rslts_df_100)] = data\n",
    "    \n",
    "    rslts_100.append({\n",
    "        'k': k, \n",
    "        'n': n, \n",
    "        'accuracy': acc,\n",
    "        'precision': pre,\n",
    "        'recall': rec,\n",
    "        'f_score': f_score,\n",
    "    })\n",
    "    \n",
    "    \n",
    "    k += 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b22c002",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rslts_df_100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3acffd",
   "metadata": {},
   "source": [
    "## n Estimator = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67902bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rslts_df_300 = pd.DataFrame(columns = [\"k\", \"Accuracy\", \"Precision\", \"Recall\", \"F_Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808c72e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rslts_300 = []\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f_scores = []\n",
    "\n",
    "k = 0\n",
    "\n",
    "print(\"N-Estimator = 300 \\n\\n\")\n",
    "\n",
    "for x in range(11):\n",
    "    an_cleaned = curated_bow.copy()\n",
    "    \n",
    "    n = round((k/100) * an_cleaned.shape[0])\n",
    "    \n",
    "    print(f\"Results after Removing top {k}% data\")\n",
    "    \n",
    "    an_cleaned = an_cleaned.iloc[n:]\n",
    "    last_col_index = len(an_cleaned.columns)-1\n",
    "    \n",
    "    X = an_cleaned.iloc[:, 0:last_col_index]\n",
    "    y = an_cleaned.iloc[:, -1]\n",
    "    \n",
    "    attrNoiseObj = dataClassifier(X, y)\n",
    "    attrNoiseObj.dataAnalysis(300)\n",
    "    \n",
    "    acc = round(attrNoiseObj.accuracy, 3)\n",
    "    pre = round(attrNoiseObj.precision, 3)\n",
    "    rec = round(attrNoiseObj.recall, 3)\n",
    "    f_score = round(attrNoiseObj.f_score, 3)\n",
    "\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Precision: {pre}\")\n",
    "    print(f\"Recall: {rec}\")\n",
    "    print(f\"F-Score: {f_score}\")\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    precisions.append(pre)\n",
    "    recalls.append(rec)\n",
    "    f_scores.append(f_score)\n",
    "    \n",
    "    data = {\n",
    "        \"k\": k,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": pre,\n",
    "        \"Recall\": rec,\n",
    "        \"F_Score\": f_score\n",
    "    }\n",
    "    \n",
    "    rslts_df_300.loc[len(rslts_df_300)] = data\n",
    "    \n",
    "    rslts_300.append({\n",
    "        'k': k, \n",
    "        'n': n, \n",
    "        'accuracy': acc,\n",
    "        'precision': pre,\n",
    "        'recall': rec,\n",
    "        'f_score': f_score,\n",
    "    })\n",
    "    \n",
    "    \n",
    "    k += 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d66c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rslts_df_300"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
